[{"title":"数据分析","date":"2022-03-18T13:03:49.043Z","url":"/2022/03/18/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/","categories":[["undefined",""]],"content":"数据分析1. 大致观察数据 上面的操作就很easy 2. 数据质量分析​ 接下来简单数据探索。在实际建模过程中，首先我们会先校验数据的正确性，并检验缺失值、异常值等情况。 数据正确性校验 所谓数据正确性，指的是数据本身是否符合基本逻辑，例如此处信用卡id作为建模分析对象独一无二的标识，我们需要验证其是否确实独一无二，并且训练集和测试集信用卡id无重复。 判断缺失值情况 异常值分析 异常值检验。由于我们尚未对数据集特征进行预处理，因此我们先查看标签列的异常值情况。首先我们可以用describe()方法查看这一列的基本统计信息： 由于是连续变量可以借助概率密度直方图进行分布的观察： ​ 能够发现，大部分用户忠诚度评分都集中在[-10,10]之间，并且基本符合正态分布，唯一需要注意的是有个别异常值取值在-30以下，该数据在后续分析中需要额外注意。我们可以简单查看有多少用户的标签数值是小于30的： 当然，对于连续变量，一般可以采用$3\\delta$原则进行异常值识别，此处我们也可以简单计算下异常值范围： &amp;emsp;&amp;emsp;需要注意的是，此处我们是围绕标签进行的异常值检测，而本案例中标签并不是自然数值测量或统计的结果（如消费金额、身高体重等），而是通过某种公式人工计算得出（详见赛题分析）。出现如此离群点极有可能是某类特殊用户的标记。因此不宜进行异常值处理，而应该将其单独视作特殊的一类，在后续建模分析时候单独对此类用户进行特征提取与建模分析。 3. 规律一致性分析&amp;emsp;&amp;emsp;接下来，进行训练集和测试集的规律一致性分析。 &amp;emsp;&amp;emsp;所谓规律一致性，指的是需要对训练集和测试集特征数据的分布进行简单比对，以“确定”两组数据是否诞生于同一个总体，即两组数据是否都遵循着背后总体的规律，即两组数据是否存在着规律一致性。 &amp;emsp;&amp;emsp;我们知道，尽管机器学习并不强调样本-总体的概念，但在训练集上挖掘到的规律要在测试集上起到预测效果，就必须要求这两部分数据受到相同规律的影响。一般来说，对于标签未知的测试集，我们可以通过特征的分布规律来判断两组数据是否取自同一总体 单变量分析 当然，我们需要同时对比训练集和测试集的四个特征，可以通过如下代码实现： 多级联合分布 ​ 接下来，我们进一步查看联合变量分布。所谓联合概率分布，指的是将离散变量两两组合，然后查看这个新变量的相对占比分布。例如特征1有0&#x2F;1两个取值水平，特征2有A&#x2F;B两个取值水平，则联合分布中就将存在0A、0B、1A、1B四种不同取值水平，然后进一步查看这四种不同取值水平出现的分布情况。 ​ 实际建模过程中，规律一致性分析是非常重要但又经常容易被忽视的一个环节。通过规律一致性分析，我们可以得出非常多的可用于后续指导后续建模的关键性意见。通常我们可以根据规律一致性分析得出以下基本结论 ​ 作用： 如果分布非常一致，则说明所有特征均取自同一整体，训练集和测试集规律拥有较高一致性，模型效果上限较高，建模过程中应该更加依靠特征工程方法和模型建模技巧提高最终预测效果 如果分布不太一致，则说明训练集和测试集规律不太一致，此时模型预测效果上限会受此影响而被限制，并且模型大概率容易过拟合，在实际建模过程中可以多考虑使用交叉验证等方式防止过拟合，并且需要注重除了通用特征工程和建模方法外的trick的使用； "},{"title":"深度推荐系统","date":"2022-03-15T13:20:16.514Z","url":"/2022/03/15/%E6%B7%B1%E5%BA%A6%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/","categories":[["undefined",""]],"content":"1. 深度学习推荐模型演化方式： 改变神经网络的复杂程度 改变特征交叉方式 wide&amp;deep模型 FM深度版本 注意力机制与推荐系统结合 序列模型与推荐模型结合 强化学习与深度学习结合 2.1 神经网络复杂程度2.1.1 Auto-rec–单层神经网络推荐模型（easy） 通过自编码器原理，还原输入的结果。 重建函数： 目标函数： 目标函数l2正则： 参考： 2.1.2 Deep Crossing模型–经典深度学习架构 应用场景 网络结构 embedding层，stacking层，multiple residual units层，scoring层 ​ 反思 embedding+多层神经网络，相较于传统的二阶特征交叉能力，deep crossing拥有深度交叉的能力 2.1.2 NeuralCF - CF与深度学习的结合先回忆一下传统的矩阵分解怎么做 物品-用户共现矩阵分解成用户向量和物品向量 向量embedding化 embedding后向量取内积（重要） 得到分数 这个模型 复杂的位置就是在第三步操作上 使用多层神经网络去替换这个卷积操作 &#x3D;&#x3D;优势&#x3D;&#x3D; 利用神经网络来拟合任意函数，灵活地组成不同的特征，按需增加或减少模型的复杂度 &#x3D;&#x3D;劣势&#x3D;&#x3D; 基于协同过滤构造,没有引入更多其他类型的特征 在实践中，防止过拟合的风险 "},{"title":"传统推荐系统","date":"2022-03-14T13:48:48.181Z","url":"/2022/03/14/%E4%BC%A0%E7%BB%9F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/","categories":[["undefined",""]],"content":"1. 推荐系统技术架构数据+模型 1.1 数据部分通过特征工程，将客户端或服务端采集到的数据进行特征处理 1.2 模型部分主题 一般由召回层，排序层，补充数据与算法层组成 2. 传统推荐模型（粗略整理）2.1 协同过滤分为 用户过滤和物品过滤 2.1.1 用户过滤（没人用）公式一 余弦相似度 公式二 皮尔逊相关系数（减少了用户评分的影响） 2.1.2 物品过滤 基于历史数据，构建用户-物品共现矩阵（m*n） 计算共现矩阵两两向量间的相似性 获得用户历史行为数据的正反馈物品列表 利用物品相似度矩阵，针对目标用户历史行为中的正反馈物品，找出相似的topK物品 对于相似度进行排序，生成最终的推荐列表 2.2 矩阵分解算法通过分解协同过滤生成的共现矩阵 得到用户和物品的隐向量 2.2.1 矩阵分解的求解方法梯度下降 目标函数 2.3 特征交叉单一特征的表达性 没有特征组合起来的表达性好 且 单一特征会损失一定量的信息 2.3.1 POLY2模型暴力将特征n个 变成了$ n^2 $ 会将数据更加稀疏 增加训练复杂度 2.3.2 FM模型-隐向量特征交叉特征交叉对于线性模型可以学习到非线性特征 隐向量 就是为每个特征 学习一个隐权重向量（latent vector） 交互使用两个向量取内积就好 优势 1. 权重参数减少到nk ​ 2. 训练复杂度降低到nk级别 2.3.3 FFM模型 特征域感知概念训练过程中，需要学习n个特征在f个域上的k维隐向量，参数 n * k * f 复杂度为 k$ n^2 $ 2.4 GBDT+LR 特征工程模型化 原始特征向量x，通过树分裂 将转化的特征类似于one-hot的向量来表示原始的特征，特征组合能力特别强 但是容易产生过拟合，以及这样的过程丢失了大量特征数值信息。 2.5 MLR 深度学习开始的曙光2.5.1 MLR与LR的区别 普通的LR模型 无法拟合我们所需的曲线 但是MLR模型正常拟合出来了 2.5.2 目标公式 如果m为1 则为普通的LR模型 当m越大 模型的拟合能力越强 而同样 需要的训练样本也变得更大 （阿里巴巴 经验12） 2.5.3 优点 端到端的非线性学习能力 模型稀疏性强 "},{"title":"centos安装","date":"2022-03-13T06:47:18.013Z","url":"/2022/03/13/1.%20centos%E5%AE%89%E8%A3%85/","categories":[["undefined",""]],"content":"个人主页  1. centos安装1.1 centos安装注意 1.2 ssh的连接 "}]